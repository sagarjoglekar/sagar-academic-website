+++
title = "FaceLift: a transparent deep learning framework to beautify urban scenes"
date = 2020-01-15T14:33:32+01:00
draft = false

# Authors. Comma separated list, e.g. `["Bob Smith", "David Jones"]`.
authors = ["**Sagar Joglekar**", "Daniele Quercia" , "Miriam Redi" , "Luca Aiello", "Tobias Kauer" , "Nishanth Sastry"]

# Publication type.
# Legend:
# 0 = Uncategorized
# 1 = Conference paper
# 2 = Journal article
# 3 = Manuscript
# 4 = Report
# 5 = Book
# 6 = Book section
publication_types = ["2"]

# Publication name and optional abbreviated version.
publication = "FaceLift: a transparent deep learning framework to beautify urban scenes"
publication_short = ""

# Abstract and optional shortened version.
abstract = "In the area of computer vision, deep learning techniques haverecently been used to predict whether urban scenes are likely tobe considered beautiful: it turns out that these techniques areable to make accurate predictions. Yet they fall short when itcomes to generating actionable insights for urban design. Tosupport  urban  interventions,  one  needs  to  go  beyondpredictingbeauty,  and  tackle  the  challenge  ofrecreatingbeauty. Unfortunately, deep learning techniques have notbeen designed with that challenge in mind. Given their‘black-box nature’, these models cannot be directly used toexplain why a particular urban scene is deemed to bebeautiful. To partly fix that, we propose a deep learningframework (which we name FaceLift1) that is able to bothbeautifyexisting urban scenes (Google Street Views) andexplainwhich urban elements make those transformed scenesbeautiful.  To  quantitatively  evaluate  our  framework,  wecannot resort to any existing metric (as the research problemat hand has never been tackled before) and need to formulatenew ones. These new metrics should ideally capture thepresence (or absence) of elements that make urban spacesgreat. Upon a review of the urban planning literature, weidentifyfivemain  metrics:  walkability,  green  spaces,openness, landmarks and visual complexity. We find that,across all the five metrics, the beautified scenes meet theexpectations set by the literature on what great spaces tendto be made of. This result is further confirmed by a 20-participant expert survey in which FaceLift has been foundto be effective in promoting citizen participation. All thissuggests that, in the future, as our framework’s componentsare  further  researched  and  become  better  and  moresophisticated, it is not hard to imagine technologies that willbe able to accurately and efficiently support architects andplanners in the design of the spaces we intuitively love."
abstract_short = ""

# Featured image thumbnail (optional)
image_preview = ""

# Is this a selected publication? (true/false)
selected = true

# Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter the filename (excluding '.md') of your project file in `content/project/`.
#   E.g. `projects = ["deep-learning"]` references `content/project/deep-learning.md`.
projects = ["theUrbanExposome"]

# Tags (optional).
#   Set `tags = []` for no tags, or use the form `tags = ["A Tag", "Another Tag"]` for one or more tags.
tags = ["Deep learning", "Data Visualization", "Urban Informatics"]

# Links (optional).
url_pdf = ""
url_preprint = ""
url_code = ""
url_dataset = ""
url_project = "http://www.goodcitylife.org/facelift/"
url_slides = ""
url_video = ""
url_poster = ""
url_source = "https://royalsocietypublishing.org/doi/10.1098/rsos.190987"

# Custom links (optional).
#   Uncomment line below to enable. For multiple links, use the form `[{...}, {...}, {...}]`.
# url_custom = [{name = "Custom Link", url = "http://example.org"}]

# Does this page contain LaTeX math? (true/false)
math = false

# Does this page require source code highlighting? (true/false)
highlight = true

# Featured image
# Place your image in the `static/img/` folder and reference its filename below, e.g. `image = "example.jpg"`.
[header]
image = ""
caption = ""

+++
